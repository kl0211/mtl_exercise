{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1817d909-bbd2-46c1-97a2-35062c507e51",
   "metadata": {},
   "source": [
    "# Task 1: Sentence Transformer Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a043d-4b2b-4e82-b6d4-c8ef9ace06f8",
   "metadata": {},
   "source": [
    "### We have a few options here. The simplest route is to use the SentenceTransformer library, which takes a transfomer model, and applies a mean pooling on the token embeddings. This requires very little decision making as it's very straightforward. To make it more interesting, I'll skip using SentenceTransformer and just use the Hugging Face Transformers library and manually code a mean pooling mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d74150-c317-41e3-95c4-ffb26793da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d05f066-7ae9-4762-9833-86feb4641c83",
   "metadata": {},
   "source": [
    "#### Load Model, Tokenizer, and dataset from Hugging Face. I chose gte-base as my model choice as it's lightweight, yet ranks high in the MTEB leaderboard. The sms spam collection is what I chose for the dataset to work with. It's lightweight and should be sufficient for NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e216f54-9b18-4209-8586-d609a51c92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-base\")\n",
    "model = AutoModel.from_pretrained(\"thenlper/gte-base\")\n",
    "df = pd.read_csv(\"hf://datasets/codesignal/sms-spam-collection/sms-spam-collection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b9e48-4141-444b-a60b-5f01f5b6b27b",
   "metadata": {},
   "source": [
    "#### A few samples of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f18c6bf-311f-4f9a-911c-0cd66de89eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      " 'Ok lar... Joking wif u oni...'\n",
      " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
      " 'U dun say so early hor... U c already then say...'\n",
      " \"Nah I don't think he goes to usf, he lives around here though\"]\n"
     ]
    }
   ],
   "source": [
    "print(df[:5][\"message\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e63d47-79ac-4d6a-9e2d-02ff3c6e6c51",
   "metadata": {},
   "source": [
    "#### Use tokenizer to convert the sentences into token ids for the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235aed84-6512-4be3-8e12-e214c991443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    df[:5][\"message\"].tolist(),  # Let's just grab the first 5 and encode those\n",
    "    padding=True,  # Make sure to pad out to the longest sequence of these inputs\n",
    "    truncation=True,  # truncate any sequence longer than what the model supports\n",
    "    return_tensors='pt'  # return pytorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1278b1-087b-439c-b529-cdaf290fab68",
   "metadata": {},
   "source": [
    "#### Run the token ids through the model to get the token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff081399-fcf3-446b-8a46-83aee7abcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # We're not training, so no need to calculate gradients\n",
    "    outputs = model(**inputs)  # Give the model 'input_ids', 'token_type_ids', and 'attention_mask'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dde515-16dd-4fb7-a271-9e94cdd72bec",
   "metadata": {},
   "source": [
    "#### To simulate what SentenceTransformers (SBERT) does with pooling, we're going to average the token embeddings in each sentence down to a single vector. But rather than simply calling `outputs.last_hidden_state.mean(dim=1)`, we only want to consider the actual tokens in each sentence, so we'll apply a mask on the token embeddings using the attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e73e8157-2a1d-4c2f-b5cf-bee6bb028a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    # We don't want to include padded tokens, so use masked_fill to zero them out.\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c542d0db-e592-41a3-a46c-d67e266802ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3814,  0.0221,  0.6724,  ...,  0.3914,  0.2581, -0.3310],\n",
      "        [ 0.4042, -0.0752,  0.3601,  ...,  0.0812,  0.3644,  0.1573],\n",
      "        [-0.0445, -0.0166,  0.9526,  ..., -0.1386, -0.1383,  0.1609],\n",
      "        [-0.4066,  0.3460,  0.5974,  ...,  0.0803,  0.4214, -0.0915],\n",
      "        [-0.0602, -0.0859,  0.0939,  ...,  0.3480,  0.8346,  0.2323]])\n",
      "torch.Size([5, 768])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)\n",
    "print(embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
